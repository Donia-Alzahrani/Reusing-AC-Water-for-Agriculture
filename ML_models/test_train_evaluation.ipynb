{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ef2939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== SVM ======\n",
      "\n",
      "====== Decision Tree ======\n",
      "\n",
      "====== Random Forest ======\n",
      "\n",
      "====== Logistic Regression ======\n",
      "\n",
      "========== Summary Table ==========\n",
      "\n",
      "Model               Set         Acc     Prec    Recall  F1      \n",
      "------------------------------------------------------------\n",
      "SVM                 Train       0.99    0.98    1.0     0.99    \n",
      "SVM                 Test        0.98    0.97    1.0     0.98    \n",
      "SVM                 Cross-Val   0.99    0.98    1.0     0.99    \n",
      "Decision Tree       Train       1.0     1.0     1.0     1.0     \n",
      "Decision Tree       Test        1.0     1.0     1.0     1.0     \n",
      "Decision Tree       Cross-Val   1.0     1.0     1.0     1.0     \n",
      "Random Forest       Train       1.0     1.0     1.0     1.0     \n",
      "Random Forest       Test        1.0     1.0     1.0     1.0     \n",
      "Random Forest       Cross-Val   1.0     1.0     1.0     1.0     \n",
      "Logistic Regression Train       0.89    0.87    0.95    0.91    \n",
      "Logistic Regression Test        0.88    0.87    0.93    0.9     \n",
      "Logistic Regression Cross-Val   0.89    0.87    0.95    0.91    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Load and prepare data\n",
    "data = pd.read_excel('model_updated.xlsx')\n",
    "X = data[['temp_sensor', 'tds_sensor', 'ph_sensor', 'turbidity_sensor']]\n",
    "y = data['fit_or_unfit']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'SVM': svm.SVC(class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200)\n",
    "}\n",
    "\n",
    "# Define scoring\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Store final results\n",
    "final_results = {}\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n====== {name} ======\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Training evaluation\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "\n",
    "    # Testing evaluation\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred)\n",
    "    test_recall = recall_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    # Cross-validation on training set\n",
    "    cv_scores = cross_validate(model, X_train_scaled, y_train, cv=5, scoring=scoring)\n",
    "    cv_accuracy = cv_scores['test_accuracy'].mean()\n",
    "    cv_precision = cv_scores['test_precision'].mean()\n",
    "    cv_recall = cv_scores['test_recall'].mean()\n",
    "    cv_f1 = cv_scores['test_f1'].mean()\n",
    "\n",
    "    # Save all results\n",
    "    final_results[name] = {\n",
    "        'Train': (train_accuracy, train_precision, train_recall, train_f1),\n",
    "        'Test': (test_accuracy, test_precision, test_recall, test_f1),\n",
    "        'Cross-Val': (cv_accuracy, cv_precision, cv_recall, cv_f1)\n",
    "    }\n",
    "\n",
    "# Display results in table format\n",
    "print(\"\\n========== Summary Table ==========\\n\")\n",
    "print(f\"{'Model':<20}{'Set':<12}{'Acc':<8}{'Prec':<8}{'Recall':<8}{'F1':<8}\")\n",
    "print(\"-\" * 60)\n",
    "for model_name, results in final_results.items():\n",
    "    for eval_type, metrics in results.items():\n",
    "        acc, prec, rec, f1 = [round(m, 2) for m in metrics]\n",
    "        print(f\"{model_name:<20}{eval_type:<12}{acc:<8}{prec:<8}{rec:<8}{f1:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0490a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== SVM ======\n",
      "\n",
      "====== Decision Tree ======\n",
      "\n",
      "====== Random Forest ======\n",
      "\n",
      "====== Logistic Regression ======\n",
      "\n",
      "========== Summary Table ==========\n",
      "\n",
      "Model               Set         Acc     Prec    Recall  F1      \n",
      "------------------------------------------------------------\n",
      "SVM                 Train       0.97    0.96    0.94    0.95    \n",
      "SVM                 Test        0.97    0.97    0.94    0.95    \n",
      "SVM                 Cross-Val   0.97    0.96    0.94    0.95    \n",
      "Decision Tree       Train       1.0     1.0     1.0     1.0     \n",
      "Decision Tree       Test        0.95    0.91    0.93    0.92    \n",
      "Decision Tree       Cross-Val   0.95    0.93    0.93    0.93    \n",
      "Random Forest       Train       1.0     1.0     1.0     1.0     \n",
      "Random Forest       Test        0.97    0.97    0.93    0.95    \n",
      "Random Forest       Cross-Val   0.97    0.99    0.93    0.96    \n",
      "Logistic Regression Train       0.87    0.8     0.79    0.8     \n",
      "Logistic Regression Test        0.86    0.82    0.77    0.8     \n",
      "Logistic Regression Cross-Val   0.87    0.8     0.79    0.79    \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Step 1: Load both datasets\n",
    "main_data = pd.read_excel('model_updated.xlsx')\n",
    "new_data = pd.read_csv('sensor_data_classified_rawan_modified.csv')\n",
    "\n",
    "# Step 2: Rename columns in new_data if needed to match main_data\n",
    "new_data = new_data.rename(columns={\n",
    "    'temp': 'temp_sensor',\n",
    "    'tds': 'tds_sensor',\n",
    "    'ph': 'ph_sensor',\n",
    "    'turbidity': 'turbidity_sensor',\n",
    "    'classification': 'fit_or_unfit'  \n",
    "})\n",
    "\n",
    "# Step 3: Ensure both datasets have the same columns\n",
    "main_data = main_data[['temp_sensor', 'tds_sensor', 'ph_sensor', 'turbidity_sensor', 'fit_or_unfit']]\n",
    "new_data = new_data[['temp_sensor', 'tds_sensor', 'ph_sensor', 'turbidity_sensor', 'fit_or_unfit']]\n",
    "\n",
    "# Step 4: Merge and shuffle\n",
    "combined_data = pd.concat([main_data, new_data], ignore_index=True)\n",
    "combined_data = combined_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Optional: Save combined dataset\n",
    "combined_data.to_excel('model_combined.xlsx', index=False)\n",
    "\n",
    "# Step 5: Prepare features and labels\n",
    "X = combined_data[['temp_sensor', 'tds_sensor', 'ph_sensor', 'turbidity_sensor']]\n",
    "y = combined_data['fit_or_unfit']\n",
    "\n",
    "# Step 6: Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 7: Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 8: Define models\n",
    "models = {\n",
    "    'SVM': svm.SVC(class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=200)\n",
    "}\n",
    "\n",
    "# Step 9: Evaluation setup\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "final_results = {}\n",
    "\n",
    "# Step 10: Train, test, and cross-validate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n====== {name} ======\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Train set evaluation\n",
    "    y_train_pred = model.predict(X_train_scaled)\n",
    "    train_metrics = (\n",
    "        accuracy_score(y_train, y_train_pred),\n",
    "        precision_score(y_train, y_train_pred),\n",
    "        recall_score(y_train, y_train_pred),\n",
    "        f1_score(y_train, y_train_pred)\n",
    "    )\n",
    "\n",
    "    # Test set evaluation\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    test_metrics = (\n",
    "        accuracy_score(y_test, y_test_pred),\n",
    "        precision_score(y_test, y_test_pred),\n",
    "        recall_score(y_test, y_test_pred),\n",
    "        f1_score(y_test, y_test_pred)\n",
    "    )\n",
    "\n",
    "    # Cross-validation on training set\n",
    "    cv_scores = cross_validate(model, X_train_scaled, y_train, cv=5, scoring=scoring)\n",
    "    cv_metrics = (\n",
    "        cv_scores['test_accuracy'].mean(),\n",
    "        cv_scores['test_precision'].mean(),\n",
    "        cv_scores['test_recall'].mean(),\n",
    "        cv_scores['test_f1'].mean()\n",
    "    )\n",
    "\n",
    "    final_results[name] = {\n",
    "        'Train': train_metrics,\n",
    "        'Test': test_metrics,\n",
    "        'Cross-Val': cv_metrics\n",
    "    }\n",
    "\n",
    "# Step 11: Print Summary Table\n",
    "print(\"\\n========== Summary Table ==========\\n\")\n",
    "print(f\"{'Model':<20}{'Set':<12}{'Acc':<8}{'Prec':<8}{'Recall':<8}{'F1':<8}\")\n",
    "print(\"-\" * 60)\n",
    "for model_name, results in final_results.items():\n",
    "    for eval_type, metrics in results.items():\n",
    "        acc, prec, rec, f1 = [round(m, 2) for m in metrics]\n",
    "        print(f\"{model_name:<20}{eval_type:<12}{acc:<8}{prec:<8}{rec:<8}{f1:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bfdeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
